{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Mergers DANN.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"GhAWyc_vyUnX","colab_type":"text"},"source":["DANN based on:\n","\n","https://github.com/ataakbari/DANN\n","\n","https://github.com/pumpikano/tf-dann/blob/master/MNIST-DANN.ipynb"]},{"cell_type":"markdown","metadata":{"id":"i_ismAY-LFaJ","colab_type":"text"},"source":["MNIST"]},{"cell_type":"code","metadata":{"id":"4-uBWK2QHcXi","colab_type":"code","outputId":"139b42b0-58d3-4885-8fb8-13cfe8b86161","executionInfo":{"status":"ok","timestamp":1583425175741,"user_tz":360,"elapsed":20240,"user":{"displayName":"Aleksandra Ciprijanovic","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhoPcTpgTc3rgP0Kt1m_QyEzKvwMCIs8O188nvi=s64","userId":"09166920093557973472"}},"colab":{"base_uri":"https://localhost:8080/","height":122}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"rgEWFTDmyb41","colab_type":"code","outputId":"55e6c42e-02e4-4549-e536-84bcd8b85d6d","executionInfo":{"status":"ok","timestamp":1583425177941,"user_tz":360,"elapsed":2185,"user":{"displayName":"Aleksandra Ciprijanovic","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhoPcTpgTc3rgP0Kt1m_QyEzKvwMCIs8O188nvi=s64","userId":"09166920093557973472"}},"colab":{"base_uri":"https://localhost:8080/","height":80}},"source":["from __future__ import print_function\n","import keras\n","import json\n","from keras.models import model_from_json\n","import tensorflow as tf\n","from keras.engine import Layer\n","import pickle as pk\n","import numpy as np\n","import keras.layers as kl\n","import keras.backend as K\n","K.set_image_data_format('channels_first')\n","import matplotlib\n","matplotlib.use('Agg')\n","import matplotlib.pyplot as plt\n","from keras.utils.vis_utils import plot_model\n","from keras.regularizers import l2"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"},{"output_type":"display_data","data":{"text/html":["<p style=\"color: red;\">\n","The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n","We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n","or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n","<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"hTbqHBag4yIg","colab_type":"code","colab":{}},"source":["#import data\n","\n","# pristine images\n","file_x_data = \"/content/drive/My Drive/DeepMergeFiles/SB00_augmented.npy\" # x data (images)\n","file_y_data = \"/content/drive/My Drive/DeepMergeFiles/SB00_augmented_y.npy\" # y data (labels) \n","\n","# noisy images\n","file_x_data_noisy = \"/content/drive/My Drive/DeepMergeFiles/SB25_augmented.npy\" \n","file_y_data_noisy = \"/content/drive/My Drive/DeepMergeFiles/SB25_augmented_y.npy\"  "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"bb0ZExBfzAlB","colab_type":"code","colab":{}},"source":["def reverse_gradient(X, hp_lambda):\n","    '''Flips the sign of the incoming gradient during training.'''\n","    try:\n","        reverse_gradient.num_calls += 1\n","    except AttributeError:\n","        reverse_gradient.num_calls = 1\n","\n","    grad_name = \"GradientReversal%d\" % reverse_gradient.num_calls\n","\n","    @tf.RegisterGradient(grad_name)\n","    def _flip_gradients(op, grad):\n","        return [tf.negative(grad) * hp_lambda]\n","\n","    g = K.get_session().graph\n","    with g.gradient_override_map({'Identity': grad_name}):\n","        y = tf.identity(X)\n","\n","    return y\n","\n","\n","class GradientReversal(Layer):\n","    '''Flip the sign of gradient during training.'''\n","    def __init__(self, hp_lambda=1.0, **kwargs):\n","        super(GradientReversal, self).__init__(**kwargs)\n","        self.supports_masking = False\n","        self.hp_lambda = hp_lambda\n","\n","    def build(self, input_shape):\n","        self.trainable_weights = []\n","\n","    def call(self, x, mask=None):\n","        return reverse_gradient(x, self.hp_lambda)\n","\n","    def get_output_shape_for(self, input_shape):\n","        return input_shape\n","\n","    def get_config(self):\n","        config = {}\n","        base_config = super(GradientReversal, self).get_config()\n","        return dict(list(base_config.items()) + list(config.items()))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Hcg5Cat0yhen","colab_type":"code","colab":{}},"source":["class DANN(object):\n","\tdef __init__(self, width=28, height=28, channels=3, classes=1, features=1, batch_size=1, grl='auto', summary=False, model_plot=False):\n","\t\t## Set Defualts\n","\t\tself.learning_phase = K.variable(1)\n","\t\tself.domain_invariant_features = None\n","\t\tself.width, self.height, self.channels = width, height, channels\n","\t\tself.input_shape = (channels, width, height)\n","\t\tself.classes = classes\n","\t\tself.features = features\n","\t\tself.batch_size = batch_size\n","\t\tself.grl = 'auto'\n","\t\t# Set reversal gradient value.\n","\t\tif grl is 'auto':\n","\t\t\tself.grl_rate = 1.0\n","\t\telse:\n","\t\t\tself.grl_rate = grl\n","\t\tself.summary = summary\n","\t\tself.model_plot = model_plot\n","\n","\t\t# Build the model\n","\t\tself.model = self._build()\n","\t\t\n","\t\t# Print and Save the model summary if requested.\n","\t\tif self.summary:\n","\t\t\tself.model.summary()\n","\t\tif self.model_plot:\n","\t\t\tplot_model(self.model, to_file='/content/drive/My Drive/Colab Notebooks/DANN/model_plot_mergers.png', show_shapes=True, show_layer_names=True)\n","\n","\tdef feature_extractor(self, inp):\n","\t\t''' \n","\t\tThis function defines the structure of the feature extractor part.\n","\t\t'''\n","\t\tout = kl.Conv2D(filters=8, kernel_size=(5, 5), padding=\"same\", strides=(1, 1), activation=\"relu\")(inp)\n","\t\tout = kl.BatchNormalization()(out)\n","\t\tout = kl.MaxPooling2D(pool_size=(2, 2), strides=None, padding='valid')(out)\n","\t\tout = kl.Dropout(0.5)(out)\n","\n","\t\tout = kl.Conv2D(filters=16, kernel_size=(3, 3), padding=\"same\", strides=(1, 1), activation=\"relu\")(out)\n","\t\tout = kl.BatchNormalization()(out)\n","\t\tout = kl.MaxPooling2D(pool_size=(2, 2), strides=None, padding='valid')(out)\n","\t\tout = kl.Dropout(0.5)(out)\n","\t\n","\t\tout = kl.Conv2D(filters=32, kernel_size=(3, 3), padding=\"same\", strides=(1, 1), activation=\"relu\")(out)\n","\t\tout = kl.BatchNormalization()(out)\n","\t\tout = kl.MaxPooling2D(pool_size=(2, 2), strides=None, padding='valid')(out)\n","\t\tout = kl.Dropout(0.5)(out)\n","\n","\t\tout = kl.Flatten()(out)\n","\n","\t\tfeature_output = kl.Dense(self.features, activation=\"relu\")(out)\n","\t\tself.domain_invariant_features = feature_output\n","\t\treturn feature_output\n","\n","\tdef classifier(self, inp):\n","\t\t''' \n","\t\tThis function defines the structure of the classifier part.\n","\t\t'''\n","\t\tout = kl.Dense(64, activation='relu')(inp)#kernel_regularizer=l2(0.0001)\n","\t\tout = kl.Dense(32, activation='relu')(out)\n","\t  #try out two classes and softmax in the last layer, and also relu in the two above\n","\t\tclassifier_output = kl.Dense(self.classes, activation=\"sigmoid\", name=\"classifier_output\")(out)\n","\t\treturn classifier_output\n","\n","\tdef discriminator(self, inp):\n","\t\t''' \n","\t\tThis function defines the structure of the discriminator part.\n","\t\t'''\n","\t\tout = kl.Dense(32, activation=\"relu\")(inp)\n","\t\tout = kl.Dropout(0.5)(out)\n","\t\tdiscriminator_output = kl.Dense(2, activation=\"sigmoid\", name=\"discriminator_output\")(out)\n","\t\treturn discriminator_output\n","\n","\tdef _build(self):\n","\t\t'''\n","\t\tThis function builds the network based on the Feature Extractor, Classifier and Discriminator parts.\n","\t\t'''\n","\t\tinp = kl.Input(shape=self.input_shape, name=\"main_input\")\n","\t\tfeature_output = self.feature_extractor(inp)\n","\t\tself.grl_layer = GradientReversal(1.0)\n","\t\tfeature_output_grl = self.grl_layer(feature_output)\n","\t\tlabeled_feature_output = kl.Lambda(lambda x, batch=self.batch_size: K.switch(K.learning_phase(), K.concatenate([x[:int(batch//2)], x[:int(batch//2)]], axis=0), x), output_shape=lambda x: x[0:])(feature_output)\n","\n","\t\t#inp = kl.Input(shape=self.input_shape, name=\"main_input\")\n","\t\t#feature_output = self.feature_extractor(inp)\n","\t\t#self.grl_layer = GradientReversal(1.0)\n","\t\t#feature_output_grl = self.grl_layer(feature_output)\n","\t\t#labeled_feature_output = kl.Lambda(lambda x, batch=self.batch_size: K.switch(K.learning_phase(), K.concatenate([x[:int(batch//2)], x[:int(batch//2)]], axis=0), x), output_shape=lambda x: x[0:])(feature_output_grl)\n","\n","\n","\n","\t\tclassifier_output = self.classifier(labeled_feature_output)\n","\t\t#discriminator_output = self.discriminator(feature_output)\n","\t\tdiscriminator_output = self.discriminator(feature_output_grl)\n","\t\tmodel = keras.models.Model(inputs=inp, outputs=[discriminator_output, classifier_output])\n","\t\treturn model\n","\n","\tdef batch_generator(self, trainX, trainY=None, batch_size=1, shuffle=True):\n","\t\t'''\n","\t\tThis function generates batches for the training purposes.\n","\t\t'''\n","\t\tif shuffle:\n","\t\t\tindex = np.random.randint(0, len(trainX) - batch_size)\n","\t\telse:\n","\t\t\tindex = np.arange(0, len(trainX), batch_size)\n","\t\twhile trainX.shape[0] > index + batch_size:\n","\t\t\tbatch_images = trainX[index : index + batch_size]\n","\t\t\tbatch_images = batch_images.reshape(batch_size, self.channels, self.width, self.height)\n","\t\t\tif trainY is not None:\n","\t\t\t\tbatch_labels = trainY[index : index + batch_size]\n","\t\t\t\tyield batch_images, batch_labels\n","\t\t\telse:\n","\t\t\t\tyield batch_images\n","\t\t\tindex += batch_size\n","\n","\tdef compile(self, optimizer):\n","\t\t'''\n","\t\tThis function compiles the model based on the given optimization method and its parameters.\n","\t\t'''\n","\t\tself.model.compile(optimizer=optimizer, loss={'classifier_output': 'binary_crossentropy', 'discriminator_output': 'binary_crossentropy'}, loss_weights={'classifier_output': 0.5, 'discriminator_output': 1.0})\n","\n","\tdef train(self, trainX, trainDX, trainY=None, epochs=1, batch_size=1, verbose=True, save_model=None):\n","\t\t'''\n","\t\tThis function trains the model using the input and target data, and saves the model if specified.\n","\t\t'''\n","\t\tmetrics_list=[]\n","\n","\t\tfor cnt in range(epochs):\n","\n","\t\t# Prepare batch data for the model training.\n","\t\t\tLabeled = self.batch_generator(trainX, trainY, batch_size=batch_size // 2)\n","\t\t\tUNLabeled = self.batch_generator(trainDX, batch_size=batch_size // 2)\n","\t\t\t\n","\t\t\t# Settings for learning rate.\n","\t\t\tp = np.float(cnt) / epochs\n","\t\t\tlr = 0.01 / (1. + 10 * p)**0.75\n","\n","\t\t\t# Settings for reverse gradient magnitude (if it's set to be automatically calculated, otherwise set by user.)\n","\t\t\tif self.grl is 'auto':\n","\t\t\t\tself.grl_layer.l = 2. / (1. + np.exp(-10. * p)) - 1\n","\n","\t\t\t# Re-compile model to adopt new learning rate and gradient reversal value.\n","\t\t\tself.compile(keras.optimizers.SGD(lr))\n","\n","\t\t\t# Loop over each batch and train the model.\n","\t\t\tfor batchX, batchY in Labeled:\n","\t\t\t\t# Get the batch for unlabeled data. If the batches are finished, regenerate the batches agian.\n","\t\t\t\ttry:\n","\t\t\t\t\tbatchDX = next(UNLabeled)\n","\t\t\t\texcept:\n","\t\t\t\t\tUNLabeled = self.batch_generator(trainDX, batch_size=batch_size // 2)\n","\t\t\t\t# Combine the labeled and unlabeled images along with the discriminative results.\n","\t\t\t\tcombined_batchX = np.concatenate((batchX, batchDX))\n","\t\t\t\tbatch2Y = np.concatenate((batchY, batchY))\n","\t\t\t\tcombined_batchY = np.concatenate((np.tile([0, 1], [batchX.shape[0], 1]), np.tile([1, 0], [batchDX.shape[0], 1])))\n","\t\t\t\t# Train the model\n","\t\t\t\tmetrics = self.model.train_on_batch({'main_input': combined_batchX}, {'classifier_output': batch2Y, 'discriminator_output':combined_batchY})\n","\n","\t\t\t# Print the losses if asked for.\n","\t\t\tif verbose:\n","\t\t\t\tprint(\"Epoch {}/{}\\n\\t[Generator_loss: {:.4}, Discriminator_loss: {:.4}, Classifier_loss: {:.4}]\".format(cnt+1, epochs, metrics[0], metrics[1], metrics[2]))\n","\t\t\t\tmetrics_list.append(metrics[:3])\n","\t\t# Save the model if asked for.\n","\t\tif save_model is not None and isinstance(save_model, str):\n","\t\t\tsave_history = ''.join((save_model[:-3], \"_history.npy\"))\n","\t\t\tnp.save(save_history, metrics_list)\n","\t\t\tprint(\"Saved history to disk\")\n","\t\t\tself.model.save(save_model)\n","\t\t\tprint(\"Saved model to disk\")\n","\t  #if save_model[-3:] is not \".h5\":\n","\t\t\t\t#save_model = ''.join((save_model, \".json\"))\n","\t\t\t#with open(save_history, 'w') as f:\n","\t\t\t#\tjson.dump(str(metrics_list), f)\n","\t\telif save_model is not None and not isinstance(save_model, str):\n","\t\t\traise TypeError(\"The input must be a filename for model settings in string format.\")\n","\n","\n","\n","\tdef evaluate(self, testX, testY=None, weight_loc=None, save_pred=None, verbose=False):\n","\t\t'''\n","\t\tThis function evaluates the model, and generates the predicted classes.\n","\t\t'''\n","\t\tif weight_loc is not None:\n","\t\t\tself.compile(keras.optimizers.SGD())\n","\t\t\tself.model.load_weights(weight_loc)\n","\t\t_, yhat_class = self.model.predict(testX, verbose=verbose)\n","\t\tif save_pred is not None:\n","\t\t\tnp.save(save_pred, yhat_class)\n","\t\tif testY is not None and len(testY) == 2:\n","\t\t\tacc = self.model.evaluate(testX, testY, verbose=verbose)\n","\t\t\tif verbose:\n","\t\t\t\tprint(\"The classifier and discriminator metrics for evaluation are [{}, {}]\".format(acc[0], acc[1]))\n","\t\telif testY is not None and len(testY) == 1:\n","\t\t\tacc = self.model.evaluate(testX, [np.ones((testY.shape[0], 2)), testY], verbose=verbose)\n","\t\t\tif verbose:\n","\t\t\t\tprint(\"The classifier metric for evaluation is {}\".format(acc[1]))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZzuFqip57zVX","colab_type":"code","colab":{}},"source":["# load data, all filters\n","x_data = np.load(file_x_data)\n","y_data = np.load(file_y_data)\n","\n","# load data, all filters, noisy\n","x_data_noisy = np.load(file_x_data_noisy)\n","y_data_noisy = np.load(file_y_data_noisy)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"phPbcmRO7zd2","colab_type":"code","colab":{}},"source":["# Divide train and test sets (the only limitation of this model is to assign even number as batch_sizes and the size of data should yield 0 remainder.)\n","trainX, testX = x_data[:12340], x_data[12340:15420]\n","trainY = keras.utils.to_categorical(y_data, num_classes=2)\n","trainY, testY = trainY[:12340], trainY[12340:15420]\n","#batch size should be 20"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Dn4nvUN1_raO","colab_type":"code","colab":{}},"source":["# make noisy images to be out of domain unlabeled data\n","trainDX = x_data_noisy[:12340]\n","testDX = x_data_noisy[12340:15420]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"zPJWiu8BAayq","colab_type":"code","colab":{}},"source":["#should I rescale to (-1,1)?\n","## Rescale -1 to 1\n","#trainX = (trainX.astype(np.float32) - 127.5) / 127.5\n","#trainDX = (trainDX.astype(np.float32) - 127.5) / 127.5\n","#testX = (testX.astype(np.float32) - 127.5) / 127.5\n","#testDX = (testDX.astype(np.float32) - 127.5) / 127.5"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"0drxrZpqASag","colab_type":"code","outputId":"8bf26bb0-ae6b-4177-e1b8-18342c930a25","executionInfo":{"status":"ok","timestamp":1583425449071,"user_tz":360,"elapsed":60178,"user":{"displayName":"Aleksandra Ciprijanovic","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhoPcTpgTc3rgP0Kt1m_QyEzKvwMCIs8O188nvi=s64","userId":"09166920093557973472"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["# Initiate the model\n","#feature number??\n","dann = DANN(summary=True, width=75, height=75, channels=2, classes=2, features=64, batch_size=20, model_plot=True)\n","# Train the model\n","dann.train(trainX, trainDX, trainY, epochs=5, batch_size=20, save_model=\"/content/drive/My Drive/Colab Notebooks/DANN/merger_model.h5\")\n","# Evaluate for pristine\n","dann.evaluate(testX, testY, save_pred=\"/content/drive/My Drive/Colab Notebooks/DANN/pristine_test.npy\", verbose=True)\n","# Evaluate for noisy\n","dann.evaluate(testDX, save_pred=\"/content/drive/My Drive/Colab Notebooks/DANN/noisy_test.npy\", verbose=True)"],"execution_count":9,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2041: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n","Model: \"model_1\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","main_input (InputLayer)         (None, 2, 75, 75)    0                                            \n","__________________________________________________________________________________________________\n","conv2d_1 (Conv2D)               (None, 8, 75, 75)    408         main_input[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_1 (BatchNor (None, 8, 75, 75)    300         conv2d_1[0][0]                   \n","__________________________________________________________________________________________________\n","max_pooling2d_1 (MaxPooling2D)  (None, 8, 37, 37)    0           batch_normalization_1[0][0]      \n","__________________________________________________________________________________________________\n","dropout_1 (Dropout)             (None, 8, 37, 37)    0           max_pooling2d_1[0][0]            \n","__________________________________________________________________________________________________\n","conv2d_2 (Conv2D)               (None, 16, 37, 37)   1168        dropout_1[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_2 (BatchNor (None, 16, 37, 37)   148         conv2d_2[0][0]                   \n","__________________________________________________________________________________________________\n","max_pooling2d_2 (MaxPooling2D)  (None, 16, 18, 18)   0           batch_normalization_2[0][0]      \n","__________________________________________________________________________________________________\n","dropout_2 (Dropout)             (None, 16, 18, 18)   0           max_pooling2d_2[0][0]            \n","__________________________________________________________________________________________________\n","conv2d_3 (Conv2D)               (None, 32, 18, 18)   4640        dropout_2[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_3 (BatchNor (None, 32, 18, 18)   72          conv2d_3[0][0]                   \n","__________________________________________________________________________________________________\n","max_pooling2d_3 (MaxPooling2D)  (None, 32, 9, 9)     0           batch_normalization_3[0][0]      \n","__________________________________________________________________________________________________\n","dropout_3 (Dropout)             (None, 32, 9, 9)     0           max_pooling2d_3[0][0]            \n","__________________________________________________________________________________________________\n","flatten_1 (Flatten)             (None, 2592)         0           dropout_3[0][0]                  \n","__________________________________________________________________________________________________\n","dense_1 (Dense)                 (None, 64)           165952      flatten_1[0][0]                  \n","__________________________________________________________________________________________________\n","gradient_reversal_1 (GradientRe (None, 64)           0           dense_1[0][0]                    \n","__________________________________________________________________________________________________\n","lambda_1 (Lambda)               (None, 64)           0           dense_1[0][0]                    \n","__________________________________________________________________________________________________\n","dense_4 (Dense)                 (None, 32)           2080        gradient_reversal_1[0][0]        \n","__________________________________________________________________________________________________\n","dense_2 (Dense)                 (None, 64)           4160        lambda_1[0][0]                   \n","__________________________________________________________________________________________________\n","dropout_4 (Dropout)             (None, 32)           0           dense_4[0][0]                    \n","__________________________________________________________________________________________________\n","dense_3 (Dense)                 (None, 32)           2080        dense_2[0][0]                    \n","__________________________________________________________________________________________________\n","discriminator_output (Dense)    (None, 2)            66          dropout_4[0][0]                  \n","__________________________________________________________________________________________________\n","classifier_output (Dense)       (None, 2)            66          dense_3[0][0]                    \n","==================================================================================================\n","Total params: 181,140\n","Trainable params: 180,880\n","Non-trainable params: 260\n","__________________________________________________________________________________________________\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3657: The name tf.log is deprecated. Please use tf.math.log instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n","\n","Epoch 1/5\n","\t[Generator_loss: 0.6648, Discriminator_loss: 0.6622, Classifier_loss: 0.005287]\n","Epoch 2/5\n","\t[Generator_loss: 0.6864, Discriminator_loss: 0.6862, Classifier_loss: 0.0003904]\n","Epoch 3/5\n","\t[Generator_loss: 0.7033, Discriminator_loss: 0.703, Classifier_loss: 0.0005381]\n","Epoch 4/5\n","\t[Generator_loss: 0.6955, Discriminator_loss: 0.6951, Classifier_loss: 0.0007461]\n","Epoch 5/5\n","\t[Generator_loss: 0.6996, Discriminator_loss: 0.6981, Classifier_loss: 0.002996]\n","Saved history to disk\n","Saved model to disk\n","3080/3080 [==============================] - 1s 236us/step\n","3080/3080 [==============================] - 0s 119us/step\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"UbhUfgHSUP21","colab_type":"code","outputId":"25d5bb62-8d17-4dd2-ef71-7c5cb2c2e416","executionInfo":{"status":"error","timestamp":1583425555508,"user_tz":360,"elapsed":3283,"user":{"displayName":"Aleksandra Ciprijanovic","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhoPcTpgTc3rgP0Kt1m_QyEzKvwMCIs8O188nvi=s64","userId":"09166920093557973472"}},"colab":{"base_uri":"https://localhost:8080/","height":184}},"source":["#Loading model\n","model = load_model('/content/drive/My Drive/Colab Notebooks/DANN/merger_model.h5', custom_objects={'GradientReversal': GradientReversal})"],"execution_count":10,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-10-bd7d13f83b5f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/My Drive/Colab Notebooks/DANN/merger_model.h5'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'GradientReversal'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mGradientReversal\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'load_model' is not defined"]}]},{"cell_type":"code","metadata":{"id":"4yJwNMOADvpO","colab_type":"code","outputId":"ae4aa94a-414d-4c18-a1b5-c9863e7e4b10","executionInfo":{"status":"ok","timestamp":1583425586318,"user_tz":360,"elapsed":868,"user":{"displayName":"Aleksandra Ciprijanovic","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhoPcTpgTc3rgP0Kt1m_QyEzKvwMCIs8O188nvi=s64","userId":"09166920093557973472"}},"colab":{"base_uri":"https://localhost:8080/","height":102}},"source":["#Load history\n","history= np.load(\"/content/drive/My Drive/Colab Notebooks/DANN/merger_model_history.npy\")\n","print(history)"],"execution_count":11,"outputs":[{"output_type":"stream","text":["[[6.6482735e-01 6.6218388e-01 5.2869851e-03]\n"," [6.8635428e-01 6.8615913e-01 3.9035029e-04]\n"," [7.0325446e-01 7.0298541e-01 5.3810747e-04]\n"," [6.9552016e-01 6.9514716e-01 7.4605376e-04]\n"," [6.9960314e-01 6.9810498e-01 2.9963348e-03]]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"3xgHfCDqEGVv","colab_type":"code","outputId":"9d35a4df-fa6a-44d9-a181-08e88b210eed","executionInfo":{"status":"ok","timestamp":1583425590910,"user_tz":360,"elapsed":1298,"user":{"displayName":"Aleksandra Ciprijanovic","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhoPcTpgTc3rgP0Kt1m_QyEzKvwMCIs8O188nvi=s64","userId":"09166920093557973472"}},"colab":{"base_uri":"https://localhost:8080/","height":314}},"source":["#plotting from history\n","#LOSS\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","\n","gen_loss=history[:,0].tolist()\n","disc_loss=history[:,1].tolist()\n","class_loss=history[:,2].tolist()\n","\n","epochs = list(range(len(history)))\n","figsize=(6,4)\n","fig, axis1 = plt.subplots(figsize=figsize)\n","plot_gen = axis1.plot(epochs, gen_loss, 'navy', label='Generator loss')\n","plot_disc = axis1.plot(epochs, disc_loss, 'deepskyblue', label=\"Discriminator loss\")\n","plot_class = axis1.plot(epochs, class_loss, 'red', label=\"Classifier loss\")\n","\n","plots = plot_gen + plot_disc + plot_class\n","labs = [l.get_label() for l in plots]\n","axis1.set_xlabel('Epoch')\n","axis1.set_ylabel('Loss')\n","plt.tight_layout()\n","axis1.legend(loc='center right')"],"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<matplotlib.legend.Legend at 0x7f160cfe5240>"]},"metadata":{"tags":[]},"execution_count":12},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAagAAAEYCAYAAAAJeGK1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"lGLSajbWfqAi","colab":{}},"source":["#import codecs\n","#import os\n","##loading history\n","#path = \"/content/drive/My Drive/Colab Notebooks/DANN/merger_model_history.json\"\n","#if os.path.exists(path): # reload history if it exists\n","#        with codecs.open(path, 'r', encoding='utf-8') as f:\n","#             n = json.loads(f.read())\n","\n","#print(n)\n","#n_num=np.fromstring(n[2:-3], dtype=float, sep=',')\n","#print(n_num)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"TRhfbNfdKTRJ","colab_type":"code","colab":{}},"source":["accc=np.load(\"/content/drive/My Drive/Colab Notebooks/DANN/noisy_test.npy\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"rx2_m08Drc0_","colab_type":"code","outputId":"7bd7a1d2-69da-4dac-feea-777202d10e24","executionInfo":{"status":"ok","timestamp":1583425603186,"user_tz":360,"elapsed":724,"user":{"displayName":"Aleksandra Ciprijanovic","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhoPcTpgTc3rgP0Kt1m_QyEzKvwMCIs8O188nvi=s64","userId":"09166920093557973472"}},"colab":{"base_uri":"https://localhost:8080/","height":187}},"source":["accc[:10]"],"execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[0.96875525, 0.03279904],\n","       [0.9679078 , 0.03497142],\n","       [0.97289133, 0.02983338],\n","       [0.9661162 , 0.0361833 ],\n","       [0.9660364 , 0.03569391],\n","       [0.96933067, 0.03440261],\n","       [0.9739928 , 0.02804968],\n","       [0.96871316, 0.03380802],\n","       [0.967237  , 0.03484663],\n","       [0.96915036, 0.03356349]], dtype=float32)"]},"metadata":{"tags":[]},"execution_count":14}]},{"cell_type":"code","metadata":{"id":"4B6qyJM2JaJN","colab_type":"code","colab":{}},"source":["acccc=np.load(\"/content/drive/My Drive/Colab Notebooks/DANN/pristine_test.npy\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"wJxzrvr9B2Um","colab_type":"code","outputId":"f184cf88-c180-4bce-fb2c-19d648e4517c","executionInfo":{"status":"ok","timestamp":1580768382963,"user_tz":360,"elapsed":270,"user":{"displayName":"Aleksandra Ciprijanovic","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mC3UiPVFrppIRAw240Oj5FQYA8auXM5t-vIVx8P=s64","userId":"09166920093557973472"}},"colab":{"base_uri":"https://localhost:8080/","height":187}},"source":["acccc[:10]"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[0.71107924, 0.23477381],\n","       [0.7114259 , 0.23465127],\n","       [0.71094656, 0.23480982],\n","       [0.7112052 , 0.23478448],\n","       [0.710945  , 0.23503843],\n","       [0.7112824 , 0.23488715],\n","       [0.7116258 , 0.23449972],\n","       [0.71158445, 0.23443541],\n","       [0.71151435, 0.23449436],\n","       [0.71136546, 0.2345699 ]], dtype=float32)"]},"metadata":{"tags":[]},"execution_count":24}]},{"cell_type":"code","metadata":{"id":"b6p6lJ2nB4xW","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}